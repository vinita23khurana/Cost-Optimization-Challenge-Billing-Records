# ğŸ“¦ Cost Optimization Challenge: Managing Billing Records in Azure Serverless Architecture
This project implements a cost-optimized, serverless architecture in Azure for managing billing records. It reduces Cosmos DB costs by tiering data into hot and cold storage, archiving rarely accessed records to Azure Blob Storage while maintaining API compatibility and availability.

/
 â”œâ”€â”€ main.tf
 â”œâ”€â”€ variables.tf
 â”œâ”€â”€ outputs.tf
 â”œâ”€â”€ modules/
 â”‚   â”œâ”€â”€ cosmos/
 â”‚   â”‚   â””â”€â”€ cosmos.tf
 â”‚   â”œâ”€â”€ storage/
 â”‚   â”‚   â””â”€â”€ blob.tf
 â”‚   â”œâ”€â”€ function/
 â”‚   â”‚   â””â”€â”€ function_app.tf
 â””â”€â”€ README.md

## ğŸ“Œ Problem Statement
Billing records are stored in Azure Cosmos DB.

Each record is up to 300 KB, and the system holds over 2 million records.

Records older than 90 days are rarely accessed but must remain available.

Cosmos DB costs have escalated due to storage and throughput needs.

# ğŸ¯ Solution Overview
Hot Data (< 3 months): Stored in Cosmos DB.

Cold Data (> 3 months): Archived to Azure Blob Storage.

Read-through Azure Function: If data is missing in Cosmos DB, it fetches from Blob Storage seamlesslyâ€”no API changes.

Cosmos DB is configured with TTL = 90 days to auto-delete archived records.

# ğŸ§± Infrastructure (Provisioned via Terraform)
Azure Cosmos DB with TTL & throughput

Azure Blob Storage for archived billing records

Azure Function App (Python-based) with read-through fallback

Modular Terraform setup with reusable components

# ğŸ“ Repository Structure
bash
Copy
Edit
.
â”œâ”€â”€ main.tf                # Root Terraform file
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ cosmos/            # Cosmos DB setup
â”‚   â”œâ”€â”€ storage/           # Blob Storage setup
â”‚   â””â”€â”€ function/          # Azure Function App with fallback logic
â”œâ”€â”€ function_code/         # Python code for read-through logic
â”œâ”€â”€ diagrams/              # Architecture diagram
â””â”€â”€ README.md              # This file
# ğŸ§ª How It Works
Billing records are written to Cosmos DB as usual.

An Azure Data Factory (or Durable Function) job archives records older than 90 days to Blob Storage.

Cosmos DB automatically purges them using TTL.

On read, the API first checks Cosmos DB. If not found, it transparently fetches the record from Blob Storage.

# ğŸš€ Deployment
bash
Copy
Edit
# Initialize and deploy Terraform infrastructure
terraform init
terraform apply
After deployment, the Azure Function is ready to serve both hot and cold data paths.

Function code is deployed from function_code/ directory (via zip or Azure CLI).

âœ… Solution Highlights
âœ… No downtime

âœ… No API contract changes

âœ… Significant cost reduction

âœ… Simple to deploy and maintain

# ğŸ“Š Architecture Diagram

# ğŸ” Security & Extensions
Secure access using Managed Identities (optional).

Blob data can be compressed (e.g., GZip) or stored in Parquet for further cost reduction.

Integrate with Azure Monitor for audit and performance tracking.

# ğŸ§© Tools Used
Azure Cosmos DB

Azure Blob Storage

Azure Functions (Python)

Terraform (Infrastructure-as-Code)
